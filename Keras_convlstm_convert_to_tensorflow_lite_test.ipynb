{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras convlstm convert to tensorflow lite test",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNfVLE6KIueKZR53ed61xCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihshin227/tensorlite_convert_test/blob/master/Keras_convlstm_convert_to_tensorflow_lite_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS6o-eI24jZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQzKI_4H4mwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3,3), input_shape=(40, 40, 3, 1), padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3,3), padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3,3), padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3,3), padding='same'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Reshape((-1, 4800)))\n",
        "model.add(tf.keras.layers.Dense(units=40))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adadelta')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRF84EGfqh3M",
        "colab_type": "code",
        "outputId": "5afc51aa-f1e5-4bcc-94fe-bae75b44e092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "inputs = np.random.random([32, 40, 40, 3, 1]).astype(np.float32)\n",
        "targets = np.random.random([32, 40]).astype(np.float32)\n",
        "\n",
        "model.fit(inputs, targets, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0265\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0056\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9890\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9906\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9848\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9821\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9782\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9668\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9655\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9613\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9482\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9439\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9431\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9424\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9418\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9411\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9373\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9349\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9279\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9132\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9126\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9120\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9078\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8968\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8956\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8949\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8943\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8938\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8902\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe87639a400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZiciw0Psc9Q",
        "colab_type": "code",
        "outputId": "1a748397-8b64-4625-9b39-3da93b2d0f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "tf_results = model(tf.constant(input_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f3f5787d6d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-04-24 01:38:26.598509: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.\n2020-04-24 01:38:26.598559: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.\n2020-04-24 01:38:26.640124: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n2020-04-24 01:38:26.640444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602952bb9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-04-24 01:38:26.640479: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-04-24 01:38:26.642541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2020-04-24 01:38:26.736051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.736988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56029aaace00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n2020-04-24 01:38:26.737021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n2020-04-24 01:38:26.737264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.737962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2020-04-24 01:38:26.738293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2020-04-24 01:38:26.739968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n2020-04-24 01:38:26.741795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n2020-04-24 01:38:26.742169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n2020-04-24 01:38:26.744348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n2020-04-24 01:38:26.745243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n2020-04-24 01:38:26.748695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n2020-04-24 01:38:26.748824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.749589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.750244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n2020-04-24 01:38:26.750348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2020-04-24 01:38:26.751671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-04-24 01:38:26.751703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-04-24 01:38:26.751712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-04-24 01:38:26.751852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.752613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-04-24 01:38:26.753346: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n2020-04-24 01:38:26.753393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10809 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\nloc(\"convolution_4@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nerror: failed while converting: 'sequential_13_conv_lst_m2d_49_while_body_98224_frozen0'\nOps that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D.\nTraceback (most recent call last):\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n    sys.exit(main(argv))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\n    enable_mlir_converter)\nException: <unknown>:0: error: loc(\"convolution_4@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_13_conv_lst_m2d_49_while_body_98224_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_13_conv_lst_m2d_50_while_body_98464_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_13_conv_lst_m2d_51_while_body_98704_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_13_conv_lst_m2d_52_while_body_98944_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: failed while converting: 'sequential_13_conv_lst_m2d_49_while_body_98224_frozen0'\nOps that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D.\n\n\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAreFnkxucOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}