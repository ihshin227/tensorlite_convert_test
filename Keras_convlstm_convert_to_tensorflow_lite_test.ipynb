{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras convlstm convert to tensorflow lite test",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPRD/IQUFjQ+wKSSPUCNbTP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihshin227/tensorlite_convert_test/blob/master/Keras_convlstm_convert_to_tensorflow_lite_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS6o-eI24jZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D\n",
        "from tensorflow.keras.layers import ConvLSTM2D\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPpcfZiZrak4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
        "                              dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # Add 3 to 7 moving squares\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # Initial position\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # Direction of motion\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # Size of the square\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
        "                             y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "                # Make it more robust by adding noise.\n",
        "                # The idea is that if during inference,\n",
        "                # the value of the pixel is not exactly one,\n",
        "                # we need to train the network to be robust and still\n",
        "                # consider it as a pixel belonging to a square.\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,\n",
        "                                 x_shift - w - 1: x_shift + w + 1,\n",
        "                                 y_shift - w - 1: y_shift + w + 1,\n",
        "                                 0] += noise_f * 0.1\n",
        "\n",
        "                # Shift the ground truth by 1\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
        "                               y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "    # Cut to a 40x40 window\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQzKI_4H4mwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   input_shape=(15, 40, 40, 1),\n",
        "                   padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(tf.keras.layers.Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adadelta())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRF84EGfqh3M",
        "colab_type": "code",
        "outputId": "e8dbab3c-ec26-4c93-ed19-aceb02a43f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
        "model.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
        "        epochs=3, validation_split=0.05)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "95/95 [==============================] - 33s 350ms/step - loss: 0.6927 - val_loss: 0.6923\n",
            "Epoch 2/3\n",
            "95/95 [==============================] - 32s 338ms/step - loss: 0.6919 - val_loss: 0.6915\n",
            "Epoch 3/3\n",
            "95/95 [==============================] - 32s 337ms/step - loss: 0.6911 - val_loss: 0.6907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbef322fdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqV6_EubbhUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import save_model\n",
        "#import tensorflow.keras.backend as K\n",
        "\n",
        "#K.set_learning_phase(0)\n",
        "\n",
        "filepath = './convlstm.h5'\n",
        "tf.keras.models.save_model(model, filepath)\n",
        "\n",
        "loaded = tf.keras.models.load_model(filepath, compile=False)\n",
        "\n",
        "export_path = './convlstm'\n",
        "loaded.save(export_path, save_format=\"tf\")\n",
        "#tf.saved_model.save(loaded, './convlstm')\n",
        "#converter = tf.lite.TFLiteConverter.from_saved_model('./convlstm')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlgy_iBwMZdS",
        "colab_type": "code",
        "outputId": "0f60ee13-7176-42f3-a17b-b6e46f9aac04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(noisy_movies[:1000].shape)\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 15, 40, 40, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJzJLk7ER0x-",
        "colab_type": "code",
        "outputId": "35722f77-4a3b-4782-aca7-206abcce8a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "tf_results = model(tf.constant(input_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-70469c7144b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mallocate_tensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllocateTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_safe_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\u001b[0m in \u001b[0;36mAllocateTensors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mAllocateTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_wrap_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreterWrapper_AllocateTensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tensorflow/lite/kernels/transpose.cc Transpose op only supports 1D-4D input arrays.Node number 2 (TRANSPOSE) failed to prepare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJFAUPUDF1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "  print(tf.keras.layers.serialize(layer))\n",
        "#tf.keras.layers.serialize(model.layers[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZiciw0Psc9Q",
        "colab_type": "code",
        "outputId": "0436c15e-6627-4322-b889-a21610cd1a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "tf_results = model(tf.constant(input_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConverterError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f3f5787d6d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         **converter_kwargs)\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[1;32m    497\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConverterError\u001b[0m: See console for info.\n2020-05-05 09:06:18.333266: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.\n2020-05-05 09:06:18.333309: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.\n2020-05-05 09:06:18.370017: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n2020-05-05 09:06:18.370384: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5620201719c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2020-05-05 09:06:18.370447: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2020-05-05 09:06:18.372587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2020-05-05 09:06:18.464434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.465254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562025660e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n2020-05-05 09:06:18.465286: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n2020-05-05 09:06:18.465488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.466297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \npciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\ncoreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n2020-05-05 09:06:18.466660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2020-05-05 09:06:18.468606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n2020-05-05 09:06:18.470127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n2020-05-05 09:06:18.470505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n2020-05-05 09:06:18.472042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n2020-05-05 09:06:18.472858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n2020-05-05 09:06:18.475977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n2020-05-05 09:06:18.476067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.476800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.477463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n2020-05-05 09:06:18.477514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n2020-05-05 09:06:18.478736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n2020-05-05 09:06:18.478783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n2020-05-05 09:06:18.478791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n2020-05-05 09:06:18.478898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.479587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2020-05-05 09:06:18.480297: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n2020-05-05 09:06:18.480355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10809 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\nloc(callsite(\"sequential/conv3d/Conv3D\"(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\":865:0) at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\":959:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py\":435:0 at callsite(\"<ipython-input-8-f3f5787d6d17>\":1:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2882:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2822:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\":2718:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\":537:0 at callsite(\"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\":208:0 at \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\":399:0)))))))))): error: 'tf.Conv3D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_conv_lst_m2d_while_body_11701_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_4@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_5@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_6@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_7@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_1@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_2@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nloc(\"convolution_3@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): error: 'tf.Conv2D' op is neither a custom op nor a flex op\nerror: failed while converting: 'main'\nOps that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): Conv3D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D.\nTraceback (most recent call last):\n  File \"/usr/local/bin/toco_from_protos\", line 8, in <module>\n    sys.exit(main())\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93, in main\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 300, in run\n    _run_main(main, args)\n  File \"/usr/local/lib/python2.7/dist-packages/absl/app.py\", line 251, in _run_main\n    sys.exit(main(argv))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56, in execute\n    enable_mlir_converter)\nException: /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:865:9: error: 'tf.Conv3D' op is neither a custom op nor a flex op\n        self._initialize(args, kwargs, add_initializers_to=initializers)\n        ^\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:959:5: note: called from\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\n    ^\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:435:5: note: called from\n    concrete_func = func.get_concrete_function()\n    ^\n<ipython-input-8-f3f5787d6d17>: note: called from\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from\n                exec(code_obj, self.user_global_ns, self.user_ns)\n                ^\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from\n                if self.run_code(code, result):\n                ^\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from\n                   interactivity=interactivity, compiler=compiler, result=result)\n                   ^\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:9: note: called from\n        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        ^\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:13: note: called from\n            res = shell.run_cell(code, store_history=store_history, silent=silent)\n            ^\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from\n                                        user_expressions, allow_stdin)\n                                        ^\n<unknown>:0: error: loc(\"convolution_4@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_conv_lst_m2d_while_body_11701_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_conv_lst_m2d_1_while_body_11925_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_conv_lst_m2d_2_while_body_12149_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_4@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_5@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_6@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_7@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_1@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_2@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: loc(\"convolution_3@sequential_conv_lst_m2d_3_while_body_12373_frozen\"): 'tf.Conv2D' op is neither a custom op nor a flex op\n<unknown>:0: error: failed while converting: 'main'\nOps that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag): Conv3D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D,Conv2D.\n\n\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C8_zZfuSnwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}